{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_rows',     1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns',  None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the database connection here: \n",
    "\n",
    "db_connection_str = ...\n",
    "connection = create_engine(db_connection_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# **Cohort Selection: Non-srugical adults**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of all HADM_IDs: 58,976\n"
     ]
    }
   ],
   "source": [
    "all_hamds_query = 'SELECT DISTINCT HADM_ID FROM ADMISSIONS'\n",
    "all_hamd_IDs_df = pd.read_sql(all_hamds_query, con=connection)\n",
    "print('Count of all HADM_IDs: {:,}'.format(len(all_hamd_IDs_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All (MetaVision/metavision):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of all CareVue    HADM_IDs: 35,632\n",
      "Count of all MetaVision HADM_IDs: 22,046\n"
     ]
    }
   ],
   "source": [
    "dbase_query = 'SELECT DISTINCT HADM_ID, DBSOURCE from ICUSTAYS'\n",
    "dbase_df    = pd.read_sql(dbase_query, con=connection)\n",
    "all_carevue_hadmIDs    = dbase_df[dbase_df.DBSOURCE=='carevue'].HADM_ID.tolist()\n",
    "all_metavision_hadmIDs = dbase_df[dbase_df.DBSOURCE=='metavision'].HADM_ID.tolist()\n",
    "print('Count of all CareVue    HADM_IDs: {:,}'.format(len(all_carevue_hadmIDs)))\n",
    "print('Count of all MetaVision HADM_IDs: {:,}'.format(len(all_metavision_hadmIDs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult HADM_IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of adult HADM_IDs:            48,150\n"
     ]
    }
   ],
   "source": [
    "adult_query = '''\n",
    "SELECT A.HADM_ID, DATEDIFF(A.ADMITTIME,DOB)/365 AS AGE_at_admission\n",
    "FROM ADMISSIONS A JOIN PATIENTS P ON A.SUBJECT_ID=P.SUBJECT_ID\n",
    "HAVING AGE_at_admission BETWEEN 18 AND 100\n",
    "'''\n",
    "\n",
    "all_adults_df      = pd.read_sql(adult_query, con=connection)\n",
    "all_adult_hadm_ids = all_adults_df.HADM_ID.unique().tolist()\n",
    "print('Count of adult HADM_IDs:            {:,}'.format(len(all_adult_hadm_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of adult CareVue    HADM_IDs: 26,197\n",
      "Count of adult MetaVision HADM_IDs: 20,811\n"
     ]
    }
   ],
   "source": [
    "adult_carevue_hadm_ids          = list(set(all_carevue_hadmIDs)   &set(all_adult_hadm_ids))\n",
    "adult_metavision_adult_hadm_ids = list(set(all_metavision_hadmIDs)&set(all_adult_hadm_ids))\n",
    "\n",
    "print('Count of adult CareVue    HADM_IDs: {:,}'.format(len(adult_carevue_hadm_ids)))\n",
    "print('Count of adult MetaVision HADM_IDs: {:,}'.format(len(adult_metavision_adult_hadm_ids)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-surgical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of adult HADM_IDs with services recorded: 48,117\n"
     ]
    }
   ],
   "source": [
    "services_query = 'SELECT HADM_ID,CURR_SERVICE FROM SERVICES WHERE HADM_ID IN {}'.format(tuple(all_adult_hadm_ids))\n",
    "services_df    = pd.read_sql_query(services_query, connection)\n",
    "print('Count of adult HADM_IDs with services recorded: {:,}'.format(len(services_df.HADM_ID.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "services_mapping = {'CMED' : True,  'CSURG':  False,  'DENT' : False, 'ENT' : False,\n",
    "                    'GU' :   False, 'GYN' :   False,  'MED' :  True,  'NB' : False,\n",
    "                    'NBB' :  False, 'NMED' :  True,   'NSURG': False, 'OBS' : False,\n",
    "                    'ORTHO': False, 'OMED' :  True,   'PSURG': False, 'PSYCH' : False,\n",
    "                    'SURG' : False, 'TRAUM' : False,  'TSURG': False, 'VSURG' : False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of non-surgical adult hadm_IDs CareVue and Metavision combnied: 24,942\n",
      "Count of adult non-surgical CareVue    HADM_IDs: 13,157\n",
      "Count of adult non-surgical MetaVision HADM_IDs: 11,640\n"
     ]
    }
   ],
   "source": [
    "services_df['Include'] = services_df.apply(lambda row: services_mapping[row['CURR_SERVICE']], axis = 1)\n",
    "df = services_df.groupby('HADM_ID')['Include'].all().reset_index()\n",
    "adult_nonSurg_hadm_IDs = df[df['Include'] == True].HADM_ID.tolist()\n",
    "print('Count of non-surgical adult hadm_IDs CareVue and Metavision combnied: {:,}'.format(len(adult_nonSurg_hadm_IDs)))\n",
    "\n",
    "\n",
    "adult_nonSurg_carevue_hadm_IDs    = list(set(adult_carevue_hadm_ids)   & set(adult_nonSurg_hadm_IDs))\n",
    "adult_nonSurg_metavision_hadm_IDs = list(set(adult_metavision_adult_hadm_ids)& set(adult_nonSurg_hadm_IDs))\n",
    "\n",
    "print('Count of adult non-surgical CareVue    HADM_IDs: {:,}'.format(len(adult_nonSurg_carevue_hadm_IDs)))\n",
    "print('Count of adult non-surgical MetaVision HADM_IDs: {:,}'.format(len(adult_nonSurg_metavision_hadm_IDs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "# **Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chartlab_vectorizer(hadm_ID, conn=connection):\n",
    "    '''\n",
    "    This functions vectorizes all relavant chart and lab items.\n",
    "    '''\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    \n",
    "    chart_item_dict = {444:'Mean_Airway_P', 224697: 'Mean_Airway_P',\n",
    "                       535:'Peak',          224695: 'Peak',        \n",
    "                       505:'PEEP',          506:    'PEEP',   220339: 'PEEP',\n",
    "                       543:'Plateau_P',     224696:'Plateau_P',    \n",
    "                       682:'TV_Obsed',      224685:'TV_Obsed',     \n",
    "                       683:'TV_Set',        224684:'TV_Set',       \n",
    "                       684:'TV_Spont',      224686:'TV_Spont',     \n",
    "                       615:'RR_Total',      224690:'RR_Total',     \n",
    "                       618:'RR',            220210:'RR',           \n",
    "                       619:'RR_Set',        224688:'RR_Set',       \n",
    "                       614:'RR_Spont',      224689:'RR_Spont',     \n",
    "                       722:'Vent_Type',     223848:'Vent_Type',    \n",
    "                       720:'Vent_Mode',     223849:'Vent_Mode',    \n",
    "                       646:'SpO2',          220277:'SpO2',         \n",
    "                       834:'SaO2_chart',    220227:'SaO2_chart',   \n",
    "                       190:'FiO2_decimal_chart',                   \n",
    "                       3420:'FiO2_percent_chart',   223835:'FiO2_percent_chart',   \n",
    "                       779:'PaO2_chart',    220224:'PaO2_chart',   \n",
    "                       778:'PaCO2_chart',   220235:'PaCO2_chart',  \n",
    "                       3810:'TCO2_chart',   225698:'TCO2_chart',   \n",
    "                       780:'PH_chart',      223830:'PH_chart',     \n",
    "                       470:'O2_Flow',       223834:'O2_Flow',      \n",
    "                       467:'O2_Device',     226732:'O2_Device',    \n",
    "                       468:'O2_Device2',                           \n",
    "                       471:'O2_Flow2',\n",
    "                      }\n",
    "    text_items = [722,223848,720,223849,467,226732,468] #These are text items for which we should get VALUE not VALUENUM\n",
    "    chart_query = '''\n",
    "        SELECT  HADM_ID,SUBJECT_ID,ITEMID,CHARTTIME, VALUE, VALUENUM\n",
    "        FROM CHARTEVENTS \n",
    "        WHERE HADM_ID = {} \n",
    "        AND ITEMID in {}\n",
    "        AND (ERROR IS Null OR ERROR = 0) AND VALUE IS NOT NULL\n",
    "        order by CHARTTIME\n",
    "    '''.format(hadm_ID, tuple(chart_item_dict.keys()))\n",
    "    \n",
    "    chart_df = pd.read_sql_query(chart_query,conn)\n",
    "    vectorized_chart_df = pd.DataFrame(columns=['HADM_ID_chart', 'SUBJECT_ID_chart']+sorted([item for item in list(set(chart_item_dict.values()))]))\n",
    "    dtms   = chart_df.CHARTTIME.unique()\n",
    "    vectorized_chart_df['CHARTTIME']        = dtms\n",
    "    vectorized_chart_df['HADM_ID_chart']    = hadm_ID\n",
    "    \n",
    "    if len(chart_df)>0: \n",
    "        vectorized_chart_df['SUBJECT_ID_chart'] = chart_df['SUBJECT_ID'].values[0] \n",
    "    else: \n",
    "        vectorized_chart_df['SUBJECT_ID_chart'] = np.NaN\n",
    "    vectorized_chart_df = vectorized_chart_df.set_index(['CHARTTIME'])\n",
    "    \n",
    "    for index,row in chart_df.iterrows():\n",
    "        if row['ITEMID'] in text_items:\n",
    "            vectorized_chart_df.loc[row['CHARTTIME'],chart_item_dict[row['ITEMID']]] = row['VALUE']\n",
    "        else:\n",
    "            vectorized_chart_df.loc[row['CHARTTIME'],chart_item_dict[row['ITEMID']]] = row['VALUENUM']\n",
    "        \n",
    "    vectorized_chart_df = vectorized_chart_df.dropna(how = 'all').reset_index()\n",
    "    vectorized_chart_df['FiO2_chart'] = vectorized_chart_df['FiO2_percent_chart'].fillna(vectorized_chart_df['FiO2_decimal_chart']*100)\n",
    "    vectorized_chart_df.drop(['FiO2_decimal_chart','FiO2_percent_chart'],axis = 1, inplace=True)\n",
    "    \n",
    "    #______________________________________________________________________________________________________________________\n",
    "    #______________________________________________________________________________________________________________________\n",
    "    #______________________________________________________________________________________________________________________\n",
    "                                                                                                                   \n",
    "    lab_item_dict = {50817:'SaO2_lab',\n",
    "                     50816:'FiO2_lab',\n",
    "                     50821:'PaO2_lab',\n",
    "                     50818:'PaCO2_lab',\n",
    "                     50804:'TCO2_lab',\n",
    "                     50820: 'PH_lab'\n",
    "                      }\n",
    "    lab_query = '''\n",
    "    SELECT  HADM_ID,SUBJECT_ID,ITEMID,CHARTTIME, VALUE, VALUENUM\n",
    "    FROM LABEVENTS \n",
    "    WHERE HADM_ID = {} \n",
    "    AND ITEMID in {}\n",
    "    AND VALUE IS NOT NULL\n",
    "    order by CHARTTIME\n",
    "    '''.format(hadm_ID, tuple(lab_item_dict.keys()))\n",
    "    lab_df = pd.read_sql_query(lab_query,conn)\n",
    "    vectorized_lab_df = pd.DataFrame(columns=['HADM_ID_lab', 'SUBJECT_ID_lab'] + [item for item in list(set(lab_item_dict.values()))])\n",
    "    dtms   = lab_df.CHARTTIME.unique() \n",
    "    vectorized_lab_df['CHARTTIME']   = dtms\n",
    "    vectorized_lab_df['HADM_ID_lab'] = hadm_ID\n",
    "    \n",
    "    if len(lab_df)>0: \n",
    "        vectorized_lab_df['SUBJECT_ID_lab'] = lab_df['SUBJECT_ID'].values[0] \n",
    "    else: \n",
    "        vectorized_lab_df['SUBJECT_ID_lab'] = np.NaN\n",
    "        \n",
    "        \n",
    "    vectorized_lab_df = vectorized_lab_df.set_index(['CHARTTIME'])\n",
    "    for index,row in lab_df.iterrows():\n",
    "        vectorized_lab_df.loc[row['CHARTTIME'],lab_item_dict[row['ITEMID']]] = row['VALUENUM']\n",
    "        \n",
    "    vectorized_lab_df = vectorized_lab_df.dropna(how = 'all').reset_index()\n",
    "    \n",
    "    combined_vectorized_df = pd.merge(vectorized_chart_df,vectorized_lab_df, how ='outer', on = 'CHARTTIME' )\n",
    "    combined_vectorized_df.sort_values(by = 'CHARTTIME', inplace = True)\n",
    "   \n",
    "    \n",
    "    # Giving priority to Lab data: \n",
    "    for measure in ['PaO2','FiO2', 'PaCO2', 'PH', 'TCO2', 'SaO2', 'HADM_ID', 'SUBJECT_ID']:\n",
    "        combined_vectorized_df[measure] = combined_vectorized_df[measure +'_lab'].fillna(combined_vectorized_df[measure +'_chart'])\n",
    "        combined_vectorized_df.drop([measure +'_lab',measure +'_chart'],axis = 1, inplace=True)\n",
    "    \n",
    "\n",
    "    # When O2_device is None flow is zero:\n",
    "    combined_vectorized_df.loc[combined_vectorized_df['O2_Device']=='None','O2_Flow']   = 0\n",
    "    combined_vectorized_df.loc[combined_vectorized_df['O2_Device2']=='None','O2_Flow2'] = 0\n",
    "\n",
    "    combined_vectorized_df = combined_vectorized_df.reindex(['SUBJECT_ID','HADM_ID'] + sorted(combined_vectorized_df.columns.drop(['HADM_ID','SUBJECT_ID'])), axis=1)\n",
    "    return combined_vectorized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_intub_finder(hadm_ID,ChartLab_vectorized_df, conn=connection):\n",
    "    '''\n",
    "    This function finds the time of intubation following the logic explained in the paper. \n",
    "    The output is the list of time of intubation based on each parameter:\n",
    "    output: [first_vent_parameter_dtm,first_O2_delivery_method_dtm, procedure_dtm, paralytics_dtm]\n",
    "    '''\n",
    "    import warnings\n",
    "    import datetime\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "    \n",
    "    ChartLab_vectorized_df = chartlab_vectorizer(hadm_ID, conn)\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    # First vent_parameter dtm\n",
    "    vent_parameter_df = \\\n",
    "    ChartLab_vectorized_df[(\\\n",
    "                 (pd.notnull(ChartLab_vectorized_df.Mean_Airway_P))|\\\n",
    "                 (pd.notnull(ChartLab_vectorized_df.Peak))|\\\n",
    "                 (pd.notnull(ChartLab_vectorized_df.PEEP))|\\\n",
    "                 (pd.notnull(ChartLab_vectorized_df.Plateau_P))|\\\n",
    "                 (pd.notnull(ChartLab_vectorized_df.TV_Obsed))|\\\n",
    "                 (pd.notnull(ChartLab_vectorized_df.TV_Set))|\\\n",
    "                 (pd.notnull(ChartLab_vectorized_df.TV_Spont))\\\n",
    "                )\\\n",
    "                & (~ChartLab_vectorized_df.Vent_Type.astype(str).str.contains(r'(NIV|VAPS|BiPAP|CPAP)', regex=True,case=False))\\\n",
    "                & (~ChartLab_vectorized_df.Vent_Mode.astype(str).str.contains(r'(NIV|VAPS|BiPAP|CPAP)', regex=True,case=False))\\\n",
    "               ]\n",
    "    first_vent_parameter_dtm = vent_parameter_df.CHARTTIME.min()\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    #  O2_delivery method:\n",
    "    O2_delivery_method_df = \\\n",
    "    ChartLab_vectorized_df[(ChartLab_vectorized_df.O2_Device == 'Ventilator')|\n",
    "                         (ChartLab_vectorized_df.O2_Device == 'Endotracheal tube')]\n",
    "    first_O2_delivery_method_dtm = O2_delivery_method_df.CHARTTIME.min()\n",
    "    \n",
    "    ##______________________________________________________________________________________________________________\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    #  Intubation procdure in the PROCEDUREEVENTS_MV, Only applies to Metavision patients. (Item 224385\tIntubation\t4,514 patients)\n",
    "    procedure_query = '''\n",
    "    SELECT ENDTIME\n",
    "    FROM PROCEDUREEVENTS_MV\n",
    "    WHERE HADM_ID = {} AND ITEMID = 224385\n",
    "    AND STATUSDESCRIPTION LIKE 'FinishedRunning'\n",
    "    '''.format(hadm_ID)\n",
    "    procedure_df = pd.read_sql(procedure_query, con=connection)\n",
    "    procedure_dtm = procedure_df.ENDTIME.min()\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    #  Paralytic drugs. We need to check if the patient is MV or CV.\n",
    "    \n",
    "    dbase = np.NaN\n",
    "    dbase_query = '''SELECT DBSOURCE from ICUSTAYS WHERE HADM_ID = {}'''.format(hadm_ID)\n",
    "    dbase_df = pd.read_sql(dbase_query, con=connection)\n",
    "    if len(dbase_df)>0:\n",
    "        dbase = dbase_df.DBSOURCE.tolist()[0]        \n",
    "    # DBSOURCE is 'metavision', 'carevue', or 'both'. There are only 150 'both's. I will just query carevue for those cases. Risk is mitigated by other T_0 factors.\n",
    "\n",
    "    if dbase == 'metavision':\n",
    "        # ITEMID\tLabel\tCNT\n",
    "        # 222168\tPropofol\t178,819             ++++++\n",
    "        # 221744\tFentanyl\t86,340              ++++++\n",
    "        # 225942\tFentanyl (Concentrate)\t45,866\n",
    "        # 221555\tCisatracurium\t9,334           ++++++\n",
    "        # 222062\tVecuronium\t664                 ++++++\n",
    "        paralytics_query = '''\n",
    "        SELECT STARTTIME\n",
    "        FROM INPUTEVENTS_MV\n",
    "        WHERE HADM_ID = {} \n",
    "        AND ( \n",
    "              (ITEMID in (222168,221744,225942) AND (ORDERCATEGORYNAME LIKE '01-Drips')) \n",
    "             OR \n",
    "              (ITEMID in (221555,222062))\n",
    "              )\n",
    "        '''.format(hadm_ID)\n",
    "        paralytics_df  = pd.read_sql(paralytics_query, con=connection)\n",
    "        paralytics_dtm = paralytics_df.STARTTIME.min()\n",
    "    else:\n",
    "        # 30131 \tPropofol\t924,614      ++++++\n",
    "        # 30118 \tFentanyl\t780,555      ++++++\n",
    "        # 30114 \tCisatracurium\t63,994   ++++++\n",
    "        # 30308 \tFentanyl Drip\t36,595\n",
    "        # 30149 \tFentanyl (Conc)\t35,526\n",
    "        # 30150 \tFentanyl Base\t14,849\n",
    "        # 30138 \tVecuronium\t5,160        ++++++\n",
    "        paralytics_query = '''\n",
    "        SELECT CHARTTIME\n",
    "        FROM INPUTEVENTS_CV\n",
    "        WHERE HADM_ID = {} \n",
    "        AND (\n",
    "              (ITEMID in (30131,30118,30308,30149,30150) AND (ORIGINALROUTE LIKE 'IV Drip' OR ORIGINALROUTE LIKE 'Intravenous Infusion' OR ORIGINALROUTE LIKE 'Drip')) \n",
    "             OR\n",
    "              (ITEMID in (30114,30138))\n",
    "            )\n",
    "        '''.format(hadm_ID)\n",
    "        paralytics_df = pd.read_sql(paralytics_query, con=connection)\n",
    "        paralytics_dtm = paralytics_df.CHARTTIME.min()\n",
    "\n",
    "    T_intubs = [first_vent_parameter_dtm,first_O2_delivery_method_dtm, procedure_dtm, paralytics_dtm]\n",
    "\n",
    "    \n",
    "    return T_intubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2114-11-29 22:00:00'), Timestamp('2114-11-29 22:00:00'), nan, nan]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chartlab_df = chartlab_vectorizer(106266, conn=connection)\n",
    "t_list = T_intub_finder(106266,chartlab_df, conn=connection)\n",
    "t_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "# **Running the code for all patients in the cohort:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----1000 of 48150 done in 12.65 minutes!\n",
      "-----2000 of 48150 done in 24.79 minutes!\n",
      "-----3000 of 48150 done in 37.43 minutes!\n",
      "-----4000 of 48150 done in 51.32 minutes!\n",
      "-----5000 of 48150 done in 63.26 minutes!\n",
      "-----6000 of 48150 done in 74.20 minutes!\n",
      "-----7000 of 48150 done in 93.58 minutes!\n",
      "-----8000 of 48150 done in 106.92 minutes!\n",
      "-----9000 of 48150 done in 121.58 minutes!\n",
      "-----10000 of 48150 done in 159.12 minutes!\n",
      "-----11000 of 48150 done in 171.61 minutes!\n",
      "-----12000 of 48150 done in 185.46 minutes!\n",
      "-----13000 of 48150 done in 198.01 minutes!\n",
      "-----14000 of 48150 done in 208.91 minutes!\n",
      "-----15000 of 48150 done in 221.77 minutes!\n",
      "-----16000 of 48150 done in 235.23 minutes!\n",
      "-----17000 of 48150 done in 247.59 minutes!\n",
      "-----18000 of 48150 done in 260.82 minutes!\n",
      "-----19000 of 48150 done in 272.26 minutes!\n",
      "-----20000 of 48150 done in 284.88 minutes!\n",
      "-----21000 of 48150 done in 299.05 minutes!\n",
      "-----22000 of 48150 done in 315.37 minutes!\n",
      "-----23000 of 48150 done in 326.97 minutes!\n",
      "-----24000 of 48150 done in 338.95 minutes!\n"
     ]
    }
   ],
   "source": [
    "not_intubated_hadmIDs      = []\n",
    "T_intubs_dict_for_analysis = dict()\n",
    "start_time                 = time.time()\n",
    "counter                    = 0\n",
    "\n",
    "for hadmID in adult_nonSurg_hadm_IDs:\n",
    "    if hadmID in T_intubs_dict_for_analysis.keys():\n",
    "        pass\n",
    "    else:\n",
    "        chartlab_df = chartlab_vectorizer(hadmID, conn=connection)\n",
    "        result      = T_intub_finder(hadmID,chartlab_df, conn=connection)\n",
    "        if any([pd.notnull(T) for T in result]):\n",
    "            T_intubs_dict_for_analysis.update({hadmID:result})\n",
    "#             print(result)\n",
    "        else:\n",
    "            not_intubated_hadmIDs.append(hadmID)\n",
    "        counter+=1\n",
    "        if counter%1000 == 0:\n",
    "            print('-----{} of {} done in {:.2f} minutes!'.format(counter,len(all_adult_hadm_ids),(time.time() - start_time)/60))\n",
    "            with open('T_intubs_dict_for_analysis','wb') as file:\n",
    "                pickle.dump(T_intubs_dict_for_analysis, file)\n",
    "            with open('not_intubated_hadmIDs','wb') as file:\n",
    "                pickle.dump(not_intubated_hadmIDs, file)\n",
    "\n",
    "with open('T_intubs_dict_for_analysis','wb') as file:\n",
    "    pickle.dump(T_intubs_dict_for_analysis, file) \n",
    "with open('not_intubated_hadmIDs','wb') as file:\n",
    "    pickle.dump(not_intubated_hadmIDs, file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "# **Analysis of $\\Delta$T:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('T_intubs_dict_for_analysis','rb') as file:\n",
    "    T_intubs_dict_for_analysis = pickle.load(file) \n",
    "with open('not_intubated_hadmIDs','rb') as file:\n",
    "    not_intubated_hadmIDs = pickle.load(file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Carevue:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of adult non-surgical CareVue HADM_IDs: 13,157\n",
      "Count of intubated carevue HADM_IDs:          4,657\n",
      "% of intubated carevue HADM_IDs:              35.4% \n"
     ]
    }
   ],
   "source": [
    "adult_nonSurg_intubated_carevue_hadm_IDs    = list(set(adult_nonSurg_carevue_hadm_IDs)   - set(not_intubated_hadmIDs))\n",
    "print('Count of adult non-surgical CareVue HADM_IDs: {:,}'.format(len(adult_nonSurg_carevue_hadm_IDs)))\n",
    "print('Count of intubated carevue HADM_IDs:          {:,}'.format(len(adult_nonSurg_intubated_carevue_hadm_IDs)))\n",
    "print('% of intubated carevue HADM_IDs:              {:.1f}% '.format(100*len(adult_nonSurg_intubated_carevue_hadm_IDs)/len(adult_nonSurg_carevue_hadm_IDs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['vent_parameter', 'O2_delivery_method','procedure', 'paralytics']\n",
    "determining_factor_list_carevue    = []\n",
    "delta_Ts_carevue                   = []\n",
    "no_vent_parameter_recorded_carevue = []\n",
    "for hadmID in adult_nonSurg_intubated_carevue_hadm_IDs:\n",
    "#     print(T_intubs_dict_for_analysis[hadmID])\n",
    "    \n",
    "    # Getting intubated hadm_IDs without a vent parameter:\n",
    "    if pd.isnull(T_intubs_dict_for_analysis[hadmID][0]):\n",
    "        no_vent_parameter_recorded_carevue.append(hadmID)\n",
    "    \n",
    "    # Getting delta T's:\n",
    "    T_intub = min([T for T in T_intubs_dict_for_analysis[hadmID] if (isinstance(T, datetime.datetime) & pd.notnull(T))])\n",
    "    determining_indices = [index for index, value in enumerate(T_intubs_dict_for_analysis[hadmID]) if value == T_intub]\n",
    "    for determining_index in determining_indices:\n",
    "        determining_factor_list_carevue.append(factors[determining_index])\n",
    "#     print(hadmID, T_intubs_dict_for_analysis[hadmID][0])\n",
    "    if pd.notnull(T_intubs_dict_for_analysis[hadmID][0]):\n",
    "        delta_T_Tintub_and_vent_parameter = (T_intubs_dict_for_analysis[hadmID][0] - T_intub).total_seconds()/3600\n",
    "        delta_Ts_carevue.append(delta_T_Tintub_and_vent_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of intubated carevue HADM_IDs with vent parameter missing:  54\n",
      "% of intubated carevue HADM_ID with vent parameter missings:      1.2%\n"
     ]
    }
   ],
   "source": [
    "print('Count of intubated carevue HADM_IDs with vent parameter missing:  {:,}'.format(len(no_vent_parameter_recorded_carevue)))\n",
    "print('% of intubated carevue HADM_ID with vent parameter missings:      {:.1f}%'.format(100*len(no_vent_parameter_recorded_carevue)/len(adult_nonSurg_intubated_carevue_hadm_IDs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vent_parameter: 4,250 (85.6%)\n",
      "procedure: 1 (0.0%)\n",
      "paralytics: 714 (14.4%)\n"
     ]
    }
   ],
   "source": [
    "counts_dict = dict(Counter(determining_factor_list_carevue))\n",
    "for factor in factors:\n",
    "    if factor in counts_dict.keys():\n",
    "        print('{}: {:,} ({:.1f}%)'.format(factor,counts_dict[factor],counts_dict[factor]/len(determining_factor_list_carevue)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero Delta_Ts (T_intub - T_vent_parameter):\n",
      "\n",
      "Count:  353 (7.7%)\n",
      "\n",
      "Range:  572.98 (0.02,573.00)\n",
      "\n",
      "Mean:   6.4 (34.8)\n",
      "\n",
      "Median: 0.50 (0.25,1.25)\n",
      "\n",
      "95 (2.0%)\n",
      "67 (1.4%)\n",
      "47 (1.0%)\n",
      "40 (0.9%)\n",
      "28 (0.6%)\n",
      "17 (0.4%)\n"
     ]
    }
   ],
   "source": [
    "print('Non-zero Delta_Ts (T_intub - T_vent_parameter):\\n')\n",
    "\n",
    "Non_zero_delta_Ts_carevue = [t for t in delta_Ts_carevue if t!=0]\n",
    "print('Count:  {:,} ({:.1f}%)'.format(len(Non_zero_delta_Ts_carevue),100*len(Non_zero_delta_Ts_carevue)/len(delta_Ts_carevue)))\n",
    "\n",
    "max_t = max(Non_zero_delta_Ts_carevue)\n",
    "min_t = min(Non_zero_delta_Ts_carevue)\n",
    "        \n",
    "print('\\nRange:  {:.2f} ({:.2f},{:.2f})'.format(max_t-min_t, min_t, max_t))\n",
    "print('\\nMean:   {:.1f} ({:.1f})'.format(np.mean(Non_zero_delta_Ts_carevue),np.std(Non_zero_delta_Ts_carevue,ddof=1)))\n",
    "median = np.median(Non_zero_delta_Ts_carevue)\n",
    "q1 =     np.percentile(Non_zero_delta_Ts_carevue,25)\n",
    "q3 =     np.percentile(Non_zero_delta_Ts_carevue,75)\n",
    "print('\\nMedian: {:.2f} ({:.2f},{:.2f})'.format(median,q1,q3))\n",
    "print('\\n{} ({:.1f}%)'.format(len([t for t in Non_zero_delta_Ts_carevue if t>1]),100*(len([t for t in Non_zero_delta_Ts_carevue if t>1])/len(adult_nonSurg_intubated_carevue_hadm_IDs))))\n",
    "print('{} ({:.1f}%)'.format(len([t for t in Non_zero_delta_Ts_carevue if t>2]),100*(len([t for t in Non_zero_delta_Ts_carevue if t>2])/len(adult_nonSurg_intubated_carevue_hadm_IDs))))\n",
    "print('{} ({:.1f}%)'.format(len([t for t in Non_zero_delta_Ts_carevue if t>4]),100*(len([t for t in Non_zero_delta_Ts_carevue if t>4])/len(adult_nonSurg_intubated_carevue_hadm_IDs))))\n",
    "print('{} ({:.1f}%)'.format(len([t for t in Non_zero_delta_Ts_carevue if t>8]),100*(len([t for t in Non_zero_delta_Ts_carevue if t>8])/len(adult_nonSurg_intubated_carevue_hadm_IDs))))\n",
    "print('{} ({:.1f}%)'.format(len([t for t in Non_zero_delta_Ts_carevue if t>12]),100*(len([t for t in Non_zero_delta_Ts_carevue if t>12])/len(adult_nonSurg_intubated_carevue_hadm_IDs))))\n",
    "print('{} ({:.1f}%)'.format(len([t for t in Non_zero_delta_Ts_carevue if t>24]),100*(len([t for t in Non_zero_delta_Ts_carevue if t>24])/len(adult_nonSurg_intubated_carevue_hadm_IDs))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MetaVision**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of adult non-surgical MetaVision HADM_IDs: 11,640\n",
      "Count of intubated metavision HADM_IDs:          3,600\n",
      "% of intubated metavision HADM_IDs:              30.9% \n"
     ]
    }
   ],
   "source": [
    "adult_nonSurg_intubated_metavision_hadm_IDs = list(set(adult_nonSurg_metavision_hadm_IDs)- set(not_intubated_hadmIDs))\n",
    "print('Count of adult non-surgical MetaVision HADM_IDs: {:,}'.format(len(adult_nonSurg_metavision_hadm_IDs)))\n",
    "print('Count of intubated metavision HADM_IDs:          {:,}'.format(len(adult_nonSurg_intubated_metavision_hadm_IDs)))\n",
    "print('% of intubated metavision HADM_IDs:              {:.1f}% '.format(100*len(adult_nonSurg_intubated_metavision_hadm_IDs)/len(adult_nonSurg_metavision_hadm_IDs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['vent_parameter', 'O2_delivery_method','procedure', 'paralytics']\n",
    "determining_factor_list_metavision    = []\n",
    "delta_Ts_metavision                   = []\n",
    "no_vent_parameter_recorded_metavision = []\n",
    "for hadmID in adult_nonSurg_intubated_metavision_hadm_IDs:\n",
    "#     print(T_intubs_dict_for_analysis[hadmID])\n",
    "    \n",
    "    # Getting intubated hadm_IDs without a vent parameter:\n",
    "    if pd.isnull(T_intubs_dict_for_analysis[hadmID][0]):\n",
    "        no_vent_parameter_recorded_metavision.append(hadmID)\n",
    "    \n",
    "    # Getting delta T's:\n",
    "    T_intub = min([T for T in T_intubs_dict_for_analysis[hadmID] if (isinstance(T, datetime.datetime) & pd.notnull(T))])\n",
    "    determining_indices = [index for index, value in enumerate(T_intubs_dict_for_analysis[hadmID]) if value == T_intub]\n",
    "    for determining_index in determining_indices:\n",
    "        determining_factor_list_metavision.append(factors[determining_index])\n",
    "#     print(hadmID, T_intubs_dict_for_analysis[hadmID][0])\n",
    "    if pd.notnull(T_intubs_dict_for_analysis[hadmID][0]):\n",
    "        delta_T_Tintub_and_vent_parameter = (T_intubs_dict_for_analysis[hadmID][0] - T_intub).total_seconds()/3600\n",
    "        delta_Ts_metavision.append(delta_T_Tintub_and_vent_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of intubated metavision HADM_IDs with vent parameter missing:  109\n",
      "% of intubated metavision HADM_ID with vent parameter missings:      3.03%\n"
     ]
    }
   ],
   "source": [
    "print('Count of intubated metavision HADM_IDs with vent parameter missing:  {:,}'.format(len(no_vent_parameter_recorded_metavision)))\n",
    "print('% of intubated metavision HADM_ID with vent parameter missings:      {:.2f}%'.format(100*len(no_vent_parameter_recorded_metavision)/len(adult_nonSurg_intubated_metavision_hadm_IDs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vent_parameter: 2,435 (50.2%)\n",
      "O2_delivery_method: 1,281 (26.4%)\n",
      "procedure: 410 (8.5%)\n",
      "paralytics: 726 (15.0%)\n"
     ]
    }
   ],
   "source": [
    "counts_dict = dict(Counter(determining_factor_list_metavision))\n",
    "for factor in factors:\n",
    "    if factor in counts_dict.keys():\n",
    "        print('{}: {:,} ({:.1f}%)'.format(factor,counts_dict[factor],counts_dict[factor]/len(determining_factor_list_metavision)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero Delta_Ts (T_i - T_v):\n",
      "\n",
      "Count:  1,056 (30.2%)\n",
      "\n",
      "Range:  310.07 (0.02,310.08)\n",
      "\n",
      "Mean:   2.5 (12.0)\n",
      "\n",
      "Median: 0.48 (0.18,1.00)\n",
      "\n",
      "253 (7.0%)\n",
      "151 (4.2%)\n",
      "105 (2.9%)\n",
      "70 (1.9%)\n",
      "49 (1.4%)\n",
      "19 (0.5%)\n"
     ]
    }
   ],
   "source": [
    "print('Non-zero Delta_Ts (T_i - T_v):\\n')\n",
    "\n",
    "Non_zero_delta_Ts_metavision = [t for t in delta_Ts_metavision if t!=0]\n",
    "print('Count:  {:,} ({:.1f}%)'.format(len(Non_zero_delta_Ts_metavision),100*len(Non_zero_delta_Ts_metavision)/len(delta_Ts_metavision)))\n",
    "\n",
    "max_t = max(Non_zero_delta_Ts_metavision)\n",
    "min_t = min(Non_zero_delta_Ts_metavision)\n",
    "        \n",
    "print('\\nRange:  {:.2f} ({:.2f},{:.2f})'.format(max_t-min_t, min_t, max_t))\n",
    "print('\\nMean:   {:.1f} ({:.1f})'.format(np.mean(Non_zero_delta_Ts_metavision),np.std(Non_zero_delta_Ts_metavision,ddof=1)))\n",
    "median = np.median(Non_zero_delta_Ts_metavision)\n",
    "q1 =     np.percentile(Non_zero_delta_Ts_metavision,25)\n",
    "q3 =     np.percentile(Non_zero_delta_Ts_metavision,75)\n",
    "print('\\nMedian: {:.2f} ({:.2f},{:.2f})'.format(median,q1,q3))\n",
    "print('\\n{} ({:.1f}%)'.format(len([t for t in Non_zero_delta_Ts_metavision if t>1]),100*(len([t for t in Non_zero_delta_Ts_metavision if t>1])/len(adult_nonSurg_intubated_metavision_hadm_IDs))))\n",
    "print('{} ({:.1f}%)'.format(len([t for t in Non_zero_delta_Ts_metavision if t>2]),100*(len([t for t in Non_zero_delta_Ts_metavision if t>2])/len(adult_nonSurg_intubated_metavision_hadm_IDs))))\n",
    "print('{} ({:.1f}%)'.format(len([t for t in Non_zero_delta_Ts_metavision if t>4]),100*(len([t for t in Non_zero_delta_Ts_metavision if t>4])/len(adult_nonSurg_intubated_metavision_hadm_IDs))))\n",
    "print('{} ({:.1f}%)'.format(len([t for t in Non_zero_delta_Ts_metavision if t>8]),100*(len([t for t in Non_zero_delta_Ts_metavision if t>8])/len(adult_nonSurg_intubated_metavision_hadm_IDs))))\n",
    "print('{} ({:.1f}%)'.format(len([t for t in Non_zero_delta_Ts_metavision if t>12]),100*(len([t for t in Non_zero_delta_Ts_metavision if t>12])/len(adult_nonSurg_intubated_metavision_hadm_IDs))))\n",
    "print('{} ({:.1f}%)'.format(len([t for t in Non_zero_delta_Ts_metavision if t>24]),100*(len([t for t in Non_zero_delta_Ts_metavision if t>24])/len(adult_nonSurg_intubated_metavision_hadm_IDs))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "# **Finding each patient's full time series:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_extub_finder(hadm_ID,ChartLab_vectorized_df, conn=connection):\n",
    "    import warnings\n",
    "    import datetime\n",
    "    \n",
    "    ChartLab_vectorized_df = chartlab_vectorizer(hadm_ID, conn)\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    # Last vent_parameter dtm\n",
    "    vent_parameter_df = ChartLab_vectorized_df[(\n",
    "        (pd.notnull(ChartLab_vectorized_df.Mean_Airway_P))|\n",
    "        (pd.notnull(ChartLab_vectorized_df.Peak))|\n",
    "        (pd.notnull(ChartLab_vectorized_df.PEEP))|\n",
    "        (pd.notnull(ChartLab_vectorized_df.Plateau_P))|\n",
    "        (pd.notnull(ChartLab_vectorized_df.TV_Obsed))|\n",
    "        (pd.notnull(ChartLab_vectorized_df.TV_Set))|\n",
    "        (pd.notnull(ChartLab_vectorized_df.TV_Spont))|\n",
    "        (ChartLab_vectorized_df.O2_Device == 'Ventilator'))\n",
    "        & (~ChartLab_vectorized_df.Vent_Type.astype(str).str.contains(r'(NIV|VAPS|BiPAP|CPAP)', regex=True,case=False))\n",
    "        & (~ChartLab_vectorized_df.Vent_Mode.astype(str).str.contains(r'(NIV|VAPS|BiPAP|CPAP)', regex=True,case=False))]\n",
    "    last_vent_parameter_dtm = vent_parameter_df.CHARTTIME.max()\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    #  Extubation procedure in the PROCEDUREEVENTS_MV, Only applies to Metavision patients.     \n",
    "        # ITEMID\tLabel\tCNT\n",
    "        # 0\t227194\tExtubation\t8328\n",
    "        # 1\t225468\tUnplanned Extubation (patient-initiated)\t327\n",
    "        # 2\t225477\tUnplanned Extubation (non-patient initiated)\t20\n",
    "    \n",
    "    procedure_query = '''\n",
    "    SELECT ENDTIME\n",
    "    FROM PROCEDUREEVENTS_MV\n",
    "    WHERE HADM_ID = {} AND ITEMID in (227194, 225468, 225477)\n",
    "    AND STATUSDESCRIPTION LIKE 'FinishedRunning'\n",
    "    '''.format(hadm_ID)\n",
    "    procedure_df = pd.read_sql(procedure_query, con=connection)\n",
    "    procedure_dtm = procedure_df.ENDTIME.min()\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    \n",
    "    # First non-vent O2 delivery method after last vent parameter:\n",
    "    NoneVent_O2_method_after_intub_df = ChartLab_vectorized_df[(ChartLab_vectorized_df.CHARTTIME>last_vent_parameter_dtm)& \\\n",
    "                                                             (pd.notnull(ChartLab_vectorized_df.O2_Device)) & \\\n",
    "                                                             (~ChartLab_vectorized_df.Vent_Mode.astype(str).str.contains(r'(ventilator)', regex=True,case=False))]\n",
    "    first_NoneVent_method_after_intub_dtm = NoneVent_O2_method_after_intub_df.CHARTTIME.min()\n",
    "    \n",
    "    \n",
    "    T_extubs = [procedure_dtm, first_NoneVent_method_after_intub_dtm]\n",
    "    try:\n",
    "        T_extub = min([T for T in T_extubs if ((isinstance(T, datetime.datetime)) & (pd.notnull(T)))])\n",
    "    except ValueError:\n",
    "        T_extub = np.NaN\n",
    "\n",
    "    \n",
    "    return T_extub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_event(ChartLab_vectorized_df, event_name, event_dtm):\n",
    "    '''\n",
    "    Sometimes things overwrite each other. For example, admission may happen at the same time as intubation. To avoid this, \n",
    "    I will not add the event to the existing dtm. I have done this with the following but later I changed it:\n",
    "    '''\n",
    "\n",
    "    if pd.notnull(event_dtm):\n",
    "        ChartLab_vectorized_df = ChartLab_vectorized_df.append({'CHARTTIME':event_dtm,'Events': event_name}, ignore_index = True)\n",
    "        return ChartLab_vectorized_df\n",
    "    else:\n",
    "        return ChartLab_vectorized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_forward_interventions (ChartLab_vectorized_df, T_Intub, T_Extub,\n",
    "                                off_vent_interventions = ['O2_Device', 'O2_Flow','O2_Device2', 'O2_Flow2','Vent_Mode','Vent_Type'],\n",
    "                                on_vent_interventions  = ['FiO2', 'PEEP', 'RR_Set','TV_Set','Vent_Mode','Vent_Type']):    \n",
    "    \n",
    "    # If intubated:\n",
    "    if pd.notnull(T_Intub):\n",
    "        # ffil off_vent_interventions before intubation:\n",
    "#         display(ChartLab_vectorized_df)\n",
    "        ChartLab_vectorized_df.loc[ChartLab_vectorized_df.CHARTTIME<T_Intub,off_vent_interventions] =\\\n",
    "        ChartLab_vectorized_df.loc[ChartLab_vectorized_df.CHARTTIME<T_Intub,off_vent_interventions].ffill()\n",
    "        \n",
    "        # If extubated:\n",
    "        if pd.notnull(T_Extub):\n",
    "            # ffil on_vent_interventions between intubation and extubation:\n",
    "            ChartLab_vectorized_df.loc[(ChartLab_vectorized_df.CHARTTIME>=T_Intub)&(ChartLab_vectorized_df.CHARTTIME<T_Extub),on_vent_interventions] =\\\n",
    "            ChartLab_vectorized_df.loc[(ChartLab_vectorized_df.CHARTTIME>=T_Intub)&(ChartLab_vectorized_df.CHARTTIME<T_Extub),on_vent_interventions].ffill()\n",
    "            # ffil off_vent_interventions after extubation:\n",
    "            ChartLab_vectorized_df.loc[ChartLab_vectorized_df.CHARTTIME>=T_Extub,off_vent_interventions] =\\\n",
    "            ChartLab_vectorized_df.loc[ChartLab_vectorized_df.CHARTTIME>=T_Extub,off_vent_interventions].ffill()\n",
    "        # If never extubated:\n",
    "        else:\n",
    "            # ffil on_vent_interventions after intubation:\n",
    "            ChartLab_vectorized_df.loc[(ChartLab_vectorized_df.CHARTTIME>=T_Intub),on_vent_interventions] =\\\n",
    "            ChartLab_vectorized_df.loc[(ChartLab_vectorized_df.CHARTTIME>=T_Intub),on_vent_interventions].ffill()\n",
    "    \n",
    "    # If not intubated in hostpital:\n",
    "    else:\n",
    "        # If an extubation seen:\n",
    "        if pd.notnull(T_Extub):\n",
    "        # ffil on_vent_interventions before extubation:\n",
    "            ChartLab_vectorized_df.loc[(ChartLab_vectorized_df.CHARTTIME<T_Extub),on_vent_interventions] =\\\n",
    "            ChartLab_vectorized_df.loc[(ChartLab_vectorized_df.CHARTTIME<T_Extub),on_vent_interventions].ffill()\n",
    "        \n",
    "        # If not extubated either:\n",
    "        else:\n",
    "            # ffil off_vent_interventions all the way\n",
    "            ChartLab_vectorized_df.loc[:,off_vent_interventions] = ChartLab_vectorized_df.loc[:,off_vent_interventions].ffill()\n",
    "    return ChartLab_vectorized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean_measure_finder(df, Time_column_name = 'hours_since_T_i', measure = 'FiO2', T_range = [0,4]):\n",
    "    '''\n",
    "    This fucntion finds the weighted mean of measure (e.g., 'PEEP') within time_windows (in days) after T0. \n",
    "    Weight of each value is duration of the value. \n",
    "    The function cuts off anything outside of the range. \n",
    "    '''    \n",
    "    if len(df)>0:\n",
    "        cumulative_T = df[Time_column_name].tolist()[0]\n",
    "        weighted_sum = cumulative_T*df[measure].tolist()[0]\n",
    "        for index, row in df.iterrows():\n",
    "            cumulative_T     += row['Length']\n",
    "            if cumulative_T  < (T_range[1]-T_range[0]):\n",
    "                weighted_sum += row['Length']*row[measure]                \n",
    "            else:\n",
    "                weighted_sum += (T_range[1]-row[Time_column_name])*row[measure]\n",
    "        return round(weighted_sum/(T_range[1]-T_range[0]),2)  # Rounding it because there are a lot of E-14, which are zero, but are counted as non-zero and messing up the reuslts\n",
    "    else:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_finder(hadm_ID, t_intubs_dict, conn=connection):\n",
    "    import warnings\n",
    "    import datetime\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "    \n",
    "    \n",
    "    time_series_df = chartlab_vectorizer(hadm_ID, connection)\n",
    "    T_intub      = min([T for T in t_intubs_dict[hadm_ID] if (isinstance(T, datetime.datetime) & pd.notnull(T))])\n",
    "#     print(T_intub)\n",
    "    T_v = t_intubs_dict[hadm_ID][0]\n",
    "    T_extub = T_extub_finder(hadm_ID,time_series_df, connection)\n",
    "    \n",
    "    if len(time_series_df)>0:\n",
    "        time_series_df['hours_since_T_i'] = (time_series_df['CHARTTIME'] - T_intub).dt.total_seconds()/3600\n",
    "        time_series_df['hours_since_T_v'] = (time_series_df['CHARTTIME'] - T_v).dt.total_seconds()/3600\n",
    "    else:\n",
    "        time_series_df['hours_since_T_i'] = np.NaN\n",
    "        time_series_df['hours_since_T_v'] = np.NaN\n",
    "    \n",
    "    time_series_df = fill_forward_interventions (time_series_df, T_intub, T_extub)\n",
    "    time_series_df['Length'] = -time_series_df['hours_since_T_i'].diff(-1)\n",
    "    print(T_intub)\n",
    "    print(T_extub)\n",
    "    return {hadm_ID: time_series_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Finding the time series for all (CareVue):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "counter    = 0\n",
    "\n",
    "time_series_dict_CareVue = dict()\n",
    "for hadmID in adult_nonSurg_intubated_carevue_hadm_IDs:\n",
    "    hadm_time_series = time_series_finder(hadmID, T_intubs_dict_for_analysis, conn=connection)\n",
    "    time_series_dict_CareVue.update(hadm_time_series)\n",
    "    counter+=1\n",
    "    if counter%500 == 0:\n",
    "        print('-----{} of {} done in {:.2f} minutes!'.format(counter,len(adult_nonSurg_intubated_carevue_hadm_IDs),(time.time() - start_time)/60))\n",
    "        with open('time_series_dict_CareVue','wb') as file:\n",
    "            pickle.dump(time_series_dict_CareVue, file)\n",
    "            \n",
    "with open('time_series_dict_CareVue','wb') as file:\n",
    "    pickle.dump(time_series_dict_CareVue, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Finding the time series for all (MetaVision):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "counter    = 0\n",
    "\n",
    "# time_series_dict_MetaVision = dict()\n",
    "for hadmID in adult_nonSurg_intubated_metavision_hadm_IDs:\n",
    "    if hadmID in time_series_dict_MetaVision.keys():\n",
    "        pass\n",
    "    else:\n",
    "        hadm_time_series = time_series_finder(hadmID, T_intubs_dict_for_analysis, conn=connection)\n",
    "        time_series_dict_MetaVision.update(hadm_time_series)\n",
    "        counter+=1\n",
    "        if counter%500 == 0:\n",
    "            print('-----{} of {} done in {:.2f} minutes!'.format(counter,len(adult_nonSurg_intubated_carevue_hadm_IDs),(time.time() - start_time)/60))\n",
    "            with open('time_series_dict_MetaVision','wb') as file:\n",
    "                pickle.dump(time_series_dict_MetaVision, file)\n",
    "            \n",
    "with open('time_series_dict_MetaVision','wb') as file:\n",
    "    pickle.dump(time_series_dict_MetaVision, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adult_nonSurg_intubated_metavision_hadm_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "# **Effect of $T_{intub}$ on clinical variables:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Effect of $T_{intub}$ on mean of different clinical measures within `T_range` of intubation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_intub_effect_analyzer(hadm_ID, T_intubs_dict, time_series_dict,\n",
    "                            measures = ['FiO2', 'PEEP', 'SpO2', 'PaO2', 'PH', 'PaCO2', 'PtoF', 'StoF','static_compliance'],\n",
    "                            T_range = [0,4], max_possible_PtoF = 700, max_possible_PEEP = 25,conn=connection):\n",
    "    '''\n",
    "    This functions finds the average of each measure during T_range (in hours) based on T_intub and T_vent_paramter.\n",
    "    '''\n",
    "    import warnings\n",
    "    import datetime\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "    \n",
    "    time_series_df = time_series_dict[hadm_ID]\n",
    "    \n",
    "    # To enhance efficiency mimic, I will keep only what we need:\n",
    "    time_series_df = time_series_df[[column for column in ['CHARTTIME','hours_since_T_i','hours_since_T_v','Length']+measures+['Plateau_P','TV_Obsed'] if column not in ['PtoF', 'StoF','static_compliance']]].copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 'FiO2' set to the first value when we had for cases with delata_t>0. \n",
    "    try:\n",
    "        time_series_df.loc[(time_series_df['hours_since_T_i']>=0)\n",
    "                           &(time_series_df['hours_since_T_v']<0)\n",
    "                           &(pd.isnull(time_series_df['FiO2'])),'FiO2'] = time_series_df[time_series_df['hours_since_T_v']>=0]['FiO2'].tolist()[0]\n",
    "    except IndexError:\n",
    "        pass\n",
    "     \n",
    "    time_series_df.loc[time_series_df['FiO2']>0,'PtoF']   = 100*time_series_df['PaO2'].astype('float64')/time_series_df['FiO2'].astype('float64')\n",
    "    time_series_df.loc[time_series_df['FiO2']>0,'StoF']   = 100*time_series_df['SpO2'].astype('float64')/time_series_df['FiO2'].astype('float64')\n",
    "    time_series_df.loc[time_series_df['Plateau_P']!=time_series_df['PEEP'],'static_compliance'] = time_series_df['TV_Obsed'].astype('float64')/(time_series_df['Plateau_P'].astype('float64')-time_series_df['PEEP'].astype('float64'))\n",
    "    \n",
    "    # Cleaning:\n",
    "    time_series_df.loc[time_series_df['PEEP'] > max_possible_PEEP, 'PEEP'] = np.NaN\n",
    "    time_series_df.loc[time_series_df['PtoF'] > max_possible_PtoF, 'PtoF'] = np.NaN \n",
    "#    \n",
    "    \n",
    "    time_series_within_T_i_range_df = time_series_df[(time_series_df['hours_since_T_i']>=T_range[0]) & (time_series_df['hours_since_T_i']<=T_range[1])].copy()\n",
    "    time_series_within_T_v_range_df = time_series_df[(time_series_df['hours_since_T_v']>=T_range[0]) & (time_series_df['hours_since_T_v']<=T_range[1])].copy()\n",
    "\n",
    "    \n",
    "    mean_within_T_i_range_dict = dict()\n",
    "    mean_within_T_v_range_dict = dict()\n",
    "    for measure in measures:\n",
    "        if measure in ['PEEP','FiO2']:\n",
    "            weighted_mean_T_i = weighted_mean_measure_finder(time_series_within_T_i_range_df.dropna(subset=[measure]), Time_column_name = 'hours_since_T_i', measure = measure, T_range = T_range)\n",
    "            mean_within_T_i_range_dict.update({measure:weighted_mean_T_i})\n",
    "            \n",
    "            weighted_mean_T_v = weighted_mean_measure_finder(time_series_within_T_v_range_df.dropna(subset=[measure]), Time_column_name = 'hours_since_T_v', measure = measure, T_range = T_range)\n",
    "            mean_within_T_v_range_dict.update({measure:weighted_mean_T_v})\n",
    "        else:\n",
    "            mean_within_T_i_range = time_series_within_T_i_range_df[measure].mean()\n",
    "            mean_within_T_i_range_dict.update({measure:mean_within_T_i_range})\n",
    "            \n",
    "            mean_within_T_v_range = time_series_within_T_v_range_df[measure].mean()\n",
    "            mean_within_T_v_range_dict.update({measure:mean_within_T_v_range})\n",
    "    \n",
    "    mean_within_T_i_range = pd.Series(mean_within_T_i_range_dict) \n",
    "    mean_within_T_v_range = pd.Series(mean_within_T_v_range_dict)\n",
    "        \n",
    "    return {hadm_ID: (mean_within_T_i_range,mean_within_T_v_range)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2199-08-03 20:44:00\n",
      "2199-08-20 07:28:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(FiO2                  66.720000\n",
       " PEEP                   5.000000\n",
       " SpO2                  99.916667\n",
       " PaO2                 193.000000\n",
       " PH                     7.370000\n",
       " PaCO2                 37.000000\n",
       " PtoF                 241.000000\n",
       " StoF                 166.500000\n",
       " static_compliance     47.600000\n",
       " dtype: float64,\n",
       " FiO2                  66.720000\n",
       " PEEP                   5.000000\n",
       " SpO2                  99.916667\n",
       " PaO2                 193.000000\n",
       " PH                     7.370000\n",
       " PaCO2                 37.000000\n",
       " PtoF                 241.000000\n",
       " StoF                 166.500000\n",
       " static_compliance     47.600000\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hadmID = random.sample(set(adult_nonSurg_hadm_IDs)-set(not_intubated_hadmIDs), k=1)[0]\n",
    "test_time_series_dict = time_series_finder(test_hadmID, T_intubs_dict_for_analysis, conn=connection)\n",
    "t_intub_effect_analyzer(test_hadmID, T_intubs_dict_for_analysis, test_time_series_dict,\n",
    "                        measures = ['FiO2', 'PEEP', 'SpO2', 'PaO2', 'PH', 'PaCO2', 'PtoF', 'StoF','static_compliance'], T_range = [0,12],\n",
    "                        max_possible_PtoF = 700, max_possible_PEEP = 25,conn=connection)[test_hadmID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_intub_effect_summarizer(ID_list, tintub_dict, time_series_dict,\n",
    "                              measures = ['FiO2', 'PEEP', 'SpO2', 'PaO2', 'PH', 'PaCO2', 'PtoF', 'StoF','static_compliance'], \n",
    "                              T_range= [0,4]):\n",
    "    '''\n",
    "    This function summarizes the effects.\n",
    "    '''\n",
    "  \n",
    "    measures_means_dict = dict()\n",
    "    start_time = time.time()\n",
    "    counter    = 0\n",
    "    for ID in ID_list:\n",
    "        result = t_intub_effect_analyzer(ID, tintub_dict, time_series_dict, measures,T_range)\n",
    "        measures_means_dict.update(result)\n",
    "        counter+=1\n",
    "        if counter%500 == 0:\n",
    "            print('-----{} of {} done in {:.2f} minutes!'.format(counter,len(ID_list),(time.time() - start_time)/60))\n",
    "    print('Measures_means_dict completed!')\n",
    "\n",
    "            \n",
    "            \n",
    "    # Printing the results -------------------------------------------------------------------------------------\n",
    "    table_dict = dict()\n",
    "    for measure_name in measures:\n",
    "        mean_T_i = []\n",
    "        mean_T_v = []\n",
    "        delta_mean_list = []\n",
    "\n",
    "        for ID in ID_list:\n",
    "            ID_T_i_measure = measures_means_dict[ID][0][measure_name]\n",
    "            ID_T_v_measure = measures_means_dict[ID][1][measure_name]\n",
    "            mean_T_i.append(ID_T_i_measure)\n",
    "            mean_T_v.append(ID_T_v_measure)\n",
    "            delta_mean_list.append(ID_T_i_measure-ID_T_v_measure)\n",
    "\n",
    "        non_nan_abs_delta_list  = [abs(i) for i in delta_mean_list if ~np.isnan(i)]\n",
    "        non_zero_abs_delta_list = [abs(i) for i in delta_mean_list if (~np.isnan(i)) and (i!=0)]\n",
    "        non_zero_delta_list     = [i for i in delta_mean_list if (~np.isnan(i)) and (i!=0)]\n",
    "\n",
    "        text = ('''{:,} ({:.1f}%)\n",
    "{:.2f} ({:.2f})\n",
    "{:.2f} ({:.2f}-{:.2f})'''.format(len(non_zero_abs_delta_list),          \n",
    "                len(non_zero_abs_delta_list)/len(non_nan_abs_delta_list)*100,\n",
    "                np.mean(non_zero_abs_delta_list), \n",
    "                np.std(non_zero_abs_delta_list,ddof=1),\n",
    "                np.median(non_zero_abs_delta_list),\n",
    "                np.percentile(non_zero_abs_delta_list,25),\n",
    "                np.percentile(non_zero_abs_delta_list,75)\n",
    "               ))\n",
    "        table_dict.update({measure_name:text})\n",
    "        \n",
    "    return (measures_means_dict, pd.Series(table_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CareVue**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('time_series_dict_CareVue','rb') as file:\n",
    "    time_series_dict_CareVue = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----500 of 4657 done in 0.37 minutes!\n",
      "-----1000 of 4657 done in 0.75 minutes!\n",
      "-----1500 of 4657 done in 1.14 minutes!\n",
      "-----2000 of 4657 done in 1.52 minutes!\n",
      "-----2500 of 4657 done in 1.90 minutes!\n",
      "-----3000 of 4657 done in 2.28 minutes!\n",
      "-----3500 of 4657 done in 2.67 minutes!\n",
      "-----4000 of 4657 done in 3.05 minutes!\n",
      "-----4500 of 4657 done in 3.43 minutes!\n",
      "Measures_means_dict completed!\n"
     ]
    }
   ],
   "source": [
    "# measures_means_dict_given_T_range_CareVue = dict()\n",
    "for t_range in [2,4,8,12]:\n",
    "    means_dict, table_results = T_intub_effect_summarizer(adult_nonSurg_intubated_carevue_hadm_IDs,T_intubs_dict_for_analysis,time_series_dict_CareVue,\n",
    "                                                          measures = ['FiO2', 'PEEP', 'SpO2', 'PaO2', 'PH', 'PaCO2', 'PtoF', 'StoF','static_compliance'], T_range= [0,t_range])\n",
    "    measures_means_dict_given_T_range_CareVue.update({t_range: means_dict})\n",
    "    table_results.to_excel('impact_table_carevue_{}_hours.xlsx'.format(t_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MetaVision:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('time_series_dict_MetaVision','rb') as file:\n",
    "    time_series_dict_MetaVision = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----500 of 3600 done in 0.33 minutes!\n",
      "-----1000 of 3600 done in 0.66 minutes!\n",
      "-----1500 of 3600 done in 1.00 minutes!\n",
      "-----2000 of 3600 done in 1.33 minutes!\n",
      "-----2500 of 3600 done in 1.66 minutes!\n",
      "-----3000 of 3600 done in 1.99 minutes!\n",
      "-----3500 of 3600 done in 2.33 minutes!\n",
      "Measures_means_dict completed!\n",
      "-----500 of 3600 done in 0.34 minutes!\n",
      "-----1000 of 3600 done in 0.67 minutes!\n",
      "-----1500 of 3600 done in 1.01 minutes!\n",
      "-----2000 of 3600 done in 1.37 minutes!\n",
      "-----2500 of 3600 done in 1.71 minutes!\n",
      "-----3000 of 3600 done in 2.05 minutes!\n",
      "-----3500 of 3600 done in 2.39 minutes!\n",
      "Measures_means_dict completed!\n",
      "-----500 of 3600 done in 0.35 minutes!\n",
      "-----1000 of 3600 done in 0.69 minutes!\n",
      "-----1500 of 3600 done in 1.04 minutes!\n",
      "-----2000 of 3600 done in 1.39 minutes!\n",
      "-----2500 of 3600 done in 1.74 minutes!\n",
      "-----3000 of 3600 done in 2.09 minutes!\n",
      "-----3500 of 3600 done in 2.44 minutes!\n",
      "Measures_means_dict completed!\n",
      "-----500 of 3600 done in 0.37 minutes!\n",
      "-----1000 of 3600 done in 0.73 minutes!\n",
      "-----1500 of 3600 done in 1.09 minutes!\n",
      "-----2000 of 3600 done in 1.44 minutes!\n",
      "-----2500 of 3600 done in 1.79 minutes!\n",
      "-----3000 of 3600 done in 2.15 minutes!\n",
      "-----3500 of 3600 done in 2.51 minutes!\n",
      "Measures_means_dict completed!\n"
     ]
    }
   ],
   "source": [
    "measures_means_dict_given_T_range_MetaVision = dict()\n",
    "for t_range in [2,4,8,12]:\n",
    "    means_dict, table_results = T_intub_effect_summarizer(adult_nonSurg_intubated_metavision_hadm_IDs,T_intubs_dict_for_analysis,time_series_dict_MetaVision,\n",
    "                                                          measures = ['FiO2', 'PEEP', 'SpO2', 'PaO2', 'PH', 'PaCO2', 'PtoF', 'StoF','static_compliance'], T_range= [0,t_range])\n",
    "    measures_means_dict_given_T_range_MetaVision.update({t_range: means_dict})\n",
    "    table_results.to_excel('impact_table_metavision_{}_hours.xlsx'.format(t_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## **Effect of $T_{intub}$ on the first recorded values of different clinical measures within `T_rang` of intubation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_intub_on_first_measurement_effect_analyzer(hadm_ID, T_intubs_dict, time_series_dict,\n",
    "                            measures = ['FiO2',  'SpO2', 'PaO2', 'PH', 'PaCO2', 'PtoF', 'StoF','static_compliance'],\n",
    "                            T_range = [0,4], max_possible_PtoF = 700, max_possible_PEEP = 25,conn=connection):\n",
    "    # This functions finds the average of each measure during T_range (in hours) based on T_intub and T_vent_paramter.\n",
    "    import warnings\n",
    "    import datetime\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "    \n",
    "    time_series_df = time_series_dict[hadm_ID]\n",
    "    \n",
    "    # To enhance efficiency mimic, I will keep only what we need:\n",
    "    time_series_df = time_series_df[[column for column in ['CHARTTIME','hours_since_T_i','hours_since_T_v','Length']+measures+['Plateau_P','TV_Obsed'] if column not in ['PtoF', 'StoF','static_compliance']]].copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 'FiO2' set to the first value when we had for cases with delata_t>0. \n",
    "    try:\n",
    "        time_series_df.loc[(time_series_df['hours_since_T_i']>=0)\n",
    "                           &(time_series_df['hours_since_T_v']<0)\n",
    "                           &(pd.isnull(time_series_df['FiO2'])),'FiO2'] = time_series_df[time_series_df['hours_since_T_v']>=0]['FiO2'].tolist()[0]\n",
    "    except IndexError:\n",
    "        pass\n",
    "     \n",
    "    time_series_df.loc[time_series_df['FiO2']>0,'PtoF']   = 100*time_series_df['PaO2'].astype('float64')/time_series_df['FiO2'].astype('float64')\n",
    "    time_series_df.loc[time_series_df['FiO2']>0,'StoF']   = 100*time_series_df['SpO2'].astype('float64')/time_series_df['FiO2'].astype('float64')\n",
    "    time_series_df.loc[time_series_df['Plateau_P']!=time_series_df['PEEP'],'static_compliance'] = time_series_df['TV_Obsed'].astype('float64')/(time_series_df['Plateau_P'].astype('float64')-time_series_df['PEEP'].astype('float64'))\n",
    "    \n",
    "    # Cleaning:\n",
    "    time_series_df.loc[time_series_df['PEEP'] > max_possible_PEEP, 'PEEP'] = np.NaN\n",
    "    time_series_df.loc[time_series_df['PtoF'] > max_possible_PtoF, 'PtoF'] = np.NaN \n",
    "#    \n",
    "    \n",
    "    time_series_within_T_i_range_df = time_series_df[(time_series_df['hours_since_T_i']>=T_range[0]) & (time_series_df['hours_since_T_i']<=T_range[1])].copy()\n",
    "    time_series_within_T_v_range_df = time_series_df[(time_series_df['hours_since_T_v']>=T_range[0]) & (time_series_df['hours_since_T_v']<=T_range[1])].copy()\n",
    "#     display(time_series_within_T_i_range_df)\n",
    "#     display(time_series_within_T_v_range_df)\n",
    "    \n",
    "    first_within_T_i_range_dict = dict()\n",
    "    first_within_T_v_range_dict = dict()\n",
    "    for measure in measures:\n",
    "        try:\n",
    "            first_within_T_i_range = time_series_within_T_i_range_df[pd.notnull(time_series_within_T_i_range_df[measure])][measure].tolist()[0]\n",
    "        except IndexError:\n",
    "            first_within_T_i_range = np.NaN\n",
    "        first_within_T_i_range_dict.update({measure:first_within_T_i_range})\n",
    "        \n",
    "        try:\n",
    "            first_within_T_v_range = time_series_within_T_v_range_df[pd.notnull(time_series_within_T_v_range_df[measure])][measure].tolist()[0]\n",
    "        \n",
    "        except IndexError:\n",
    "            first_within_T_v_range = np.NaN\n",
    "        first_within_T_v_range_dict.update({measure:first_within_T_v_range})\n",
    "    \n",
    "    first_within_T_i_range = pd.Series(first_within_T_i_range_dict) \n",
    "    first_within_T_v_range = pd.Series(first_within_T_v_range_dict)\n",
    "       \n",
    "    return {hadm_ID: (first_within_T_i_range,first_within_T_v_range)}\n",
    "\n",
    "def T_intub_effect_on_first_summarizer(ID_list, tintub_dict, time_series_dict, measures = ['FiO2', 'SpO2', 'PaO2', 'PH', 'PaCO2', 'PtoF', 'StoF'], T_range= [0,4]):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    measures_means_dict = dict()\n",
    "    start_time = time.time()\n",
    "    counter    = 0\n",
    "    for ID in ID_list:\n",
    "        result = t_intub_on_first_measurement_effect_analyzer(ID, tintub_dict, time_series_dict, measures,T_range)\n",
    "        measures_means_dict.update(result)\n",
    "        counter+=1\n",
    "        if counter%500 == 0:\n",
    "            print('-----{} of {} done in {:.2f} minutes!'.format(counter,len(ID_list),(time.time() - start_time)/60))\n",
    "    print('Measures_means_dict completed!')\n",
    "        \n",
    "    # Printing the results -------------------------------------------------------------------------------------\n",
    "    table_dict = dict()\n",
    "    for measure_name in measures:\n",
    "        mean_T_i = []\n",
    "        mean_T_v = []\n",
    "        delta_mean_list = []\n",
    "\n",
    "        for ID in ID_list:\n",
    "            ID_T_i_measure = measures_means_dict[ID][0][measure_name]\n",
    "            ID_T_v_measure = measures_means_dict[ID][1][measure_name]\n",
    "            mean_T_i.append(ID_T_i_measure)\n",
    "            mean_T_v.append(ID_T_v_measure)\n",
    "            delta_mean_list.append(ID_T_i_measure-ID_T_v_measure)\n",
    "    #         if ID_T_i_measure-ID_T_v_measure>100:\n",
    "    #             print(ID)\n",
    "\n",
    "        non_nan_abs_delta_list  = [abs(i) for i in delta_mean_list if ~np.isnan(i)]\n",
    "        non_zero_abs_delta_list = [abs(i) for i in delta_mean_list if (~np.isnan(i)) and (i!=0)]\n",
    "        non_zero_delta_list     = [i for i in delta_mean_list if (~np.isnan(i)) and (i!=0)]\n",
    "        \n",
    "        try:\n",
    "            print('====================')\n",
    "            print(measure_name)\n",
    "            print('Count of missing x-hour mean {} based on T_i: {:,}'.format(measure_name,len([i for i in mean_T_i if np.isnan(i)])))\n",
    "            print('Count of missing x-hour mean {} based on T_v: {:,}'.format(measure_name,len([i for i in mean_T_v if np.isnan(i)])))\n",
    "\n",
    "            print('''\n",
    "    Percent positive: {:.2f}%\n",
    "    Percent negative: {:.2f}%'''.format(\n",
    "            100*len([i for i in non_zero_delta_list if i>0])/len(non_zero_delta_list),\n",
    "            100*len([i for i in non_zero_delta_list if i<0])/len(non_zero_delta_list)\n",
    "             ))\n",
    "            text = ('''{:,} ({:.1f}%)\n",
    "    {:.2f} ({:.2f})\n",
    "    {:.2f} ({:.2f}-{:.2f})'''.format(len(non_zero_abs_delta_list),          \n",
    "                    len(non_zero_abs_delta_list)/len(non_nan_abs_delta_list)*100,\n",
    "                    np.mean(non_zero_abs_delta_list), \n",
    "                    np.std(non_zero_abs_delta_list,ddof=1),\n",
    "                    np.median(non_zero_abs_delta_list),\n",
    "                    np.percentile(non_zero_abs_delta_list,25),\n",
    "                    np.percentile(non_zero_abs_delta_list,75)\n",
    "                   ))\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "        \n",
    "        table_dict.update({measure_name:text})\n",
    "#         print(text)\n",
    "        \n",
    "    return (measures_means_dict, pd.Series(table_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CareVue**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('time_series_dict_CareVue','rb') as file:\n",
    "    time_series_dict_CareVue = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----500 of 4657 done in 0.40 minutes!\n",
      "-----1000 of 4657 done in 0.81 minutes!\n",
      "-----1500 of 4657 done in 1.22 minutes!\n",
      "-----2000 of 4657 done in 1.61 minutes!\n",
      "-----2500 of 4657 done in 1.99 minutes!\n",
      "-----3000 of 4657 done in 2.39 minutes!\n",
      "-----3500 of 4657 done in 2.80 minutes!\n",
      "-----4000 of 4657 done in 3.22 minutes!\n",
      "-----4500 of 4657 done in 3.62 minutes!\n",
      "Measures_means_dict completed!\n",
      "====================\n",
      "FiO2\n",
      "Count of missing x-hour mean FiO2 based on T_i: 103\n",
      "Count of missing x-hour mean FiO2 based on T_v: 127\n",
      "\n",
      "    Percent positive: 77.78%\n",
      "    Percent negative: 22.22%\n",
      "====================\n",
      "SpO2\n",
      "Count of missing x-hour mean SpO2 based on T_i: 78\n",
      "Count of missing x-hour mean SpO2 based on T_v: 120\n",
      "\n",
      "    Percent positive: 45.11%\n",
      "    Percent negative: 54.89%\n",
      "====================\n",
      "PaO2\n",
      "Count of missing x-hour mean PaO2 based on T_i: 1,404\n",
      "Count of missing x-hour mean PaO2 based on T_v: 1,414\n",
      "\n",
      "    Percent positive: 48.21%\n",
      "    Percent negative: 51.79%\n",
      "====================\n",
      "PH\n",
      "Count of missing x-hour mean PH based on T_i: 1,376\n",
      "Count of missing x-hour mean PH based on T_v: 1,386\n",
      "\n",
      "    Percent positive: 35.19%\n",
      "    Percent negative: 64.81%\n",
      "====================\n",
      "PaCO2\n",
      "Count of missing x-hour mean PaCO2 based on T_i: 1,404\n",
      "Count of missing x-hour mean PaCO2 based on T_v: 1,414\n",
      "\n",
      "    Percent positive: 58.00%\n",
      "    Percent negative: 42.00%\n",
      "====================\n",
      "PtoF\n",
      "Count of missing x-hour mean PtoF based on T_i: 2,907\n",
      "Count of missing x-hour mean PtoF based on T_v: 2,928\n",
      "\n",
      "    Percent positive: 38.71%\n",
      "    Percent negative: 61.29%\n",
      "====================\n",
      "StoF\n",
      "Count of missing x-hour mean StoF based on T_i: 498\n",
      "Count of missing x-hour mean StoF based on T_v: 529\n",
      "\n",
      "    Percent positive: 39.20%\n",
      "    Percent negative: 60.80%\n",
      "====================\n",
      "PEEP\n",
      "Count of missing x-hour mean PEEP based on T_i: 80\n",
      "Count of missing x-hour mean PEEP based on T_v: 86\n",
      "\n",
      "    Percent positive: 69.57%\n",
      "    Percent negative: 30.43%\n"
     ]
    }
   ],
   "source": [
    "measures_firsts_dict_given_T_range_CareVue = dict()\n",
    "\n",
    "for t_range in [4]:\n",
    "    firsts_dict, firsts_table_results = T_intub_effect_on_first_summarizer(adult_nonSurg_intubated_carevue_hadm_IDs,T_intubs_dict_for_analysis,\n",
    "                                                                           time_series_dict_CareVue,\n",
    "                                                                           measures = ['FiO2', 'SpO2', 'PaO2', 'PH', 'PaCO2', 'PtoF', 'StoF','PEEP'], T_range= [0,t_range])\n",
    "    measures_firsts_dict_given_T_range_CareVue.update({t_range: firsts_dict})\n",
    "    firsts_table_results.to_excel('impact_table_carevue_first_{}_hours.xlsx'.format(t_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MetaVision**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('time_series_dict_MetaVision','rb') as file:\n",
    "    time_series_dict_MetaVision = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----500 of 3600 done in 0.39 minutes!\n",
      "-----1000 of 3600 done in 0.78 minutes!\n",
      "-----1500 of 3600 done in 1.17 minutes!\n",
      "-----2000 of 3600 done in 1.54 minutes!\n",
      "-----2500 of 3600 done in 1.91 minutes!\n",
      "-----3000 of 3600 done in 2.29 minutes!\n",
      "-----3500 of 3600 done in 2.66 minutes!\n",
      "Measures_means_dict completed!\n",
      "====================\n",
      "FiO2\n",
      "Count of missing x-hour mean FiO2 based on T_i: 92\n",
      "Count of missing x-hour mean FiO2 based on T_v: 169\n",
      "\n",
      "    Percent positive: 77.11%\n",
      "    Percent negative: 22.89%\n",
      "====================\n",
      "SpO2\n",
      "Count of missing x-hour mean SpO2 based on T_i: 42\n",
      "Count of missing x-hour mean SpO2 based on T_v: 138\n",
      "\n",
      "    Percent positive: 45.51%\n",
      "    Percent negative: 54.49%\n",
      "====================\n",
      "PaO2\n",
      "Count of missing x-hour mean PaO2 based on T_i: 1,392\n",
      "Count of missing x-hour mean PaO2 based on T_v: 1,449\n",
      "\n",
      "    Percent positive: 50.51%\n",
      "    Percent negative: 49.49%\n",
      "====================\n",
      "PH\n",
      "Count of missing x-hour mean PH based on T_i: 1,362\n",
      "Count of missing x-hour mean PH based on T_v: 1,419\n",
      "\n",
      "    Percent positive: 32.99%\n",
      "    Percent negative: 67.01%\n",
      "====================\n",
      "PaCO2\n",
      "Count of missing x-hour mean PaCO2 based on T_i: 1,392\n",
      "Count of missing x-hour mean PaCO2 based on T_v: 1,449\n",
      "\n",
      "    Percent positive: 65.26%\n",
      "    Percent negative: 34.74%\n",
      "====================\n",
      "PtoF\n",
      "Count of missing x-hour mean PtoF based on T_i: 2,558\n",
      "Count of missing x-hour mean PtoF based on T_v: 2,680\n",
      "\n",
      "    Percent positive: 49.02%\n",
      "    Percent negative: 50.98%\n",
      "====================\n",
      "StoF\n",
      "Count of missing x-hour mean StoF based on T_i: 554\n",
      "Count of missing x-hour mean StoF based on T_v: 609\n",
      "\n",
      "    Percent positive: 34.00%\n",
      "    Percent negative: 66.00%\n",
      "====================\n",
      "PEEP\n",
      "Count of missing x-hour mean PEEP based on T_i: 128\n",
      "Count of missing x-hour mean PEEP based on T_v: 171\n",
      "\n",
      "    Percent positive: 73.58%\n",
      "    Percent negative: 26.42%\n"
     ]
    }
   ],
   "source": [
    "measures_firsts_dict_given_T_range_MetaVision = dict()\n",
    "\n",
    "for t_range in [4]:\n",
    "    firsts_dict, firsts_table_results = T_intub_effect_on_first_summarizer(adult_nonSurg_intubated_metavision_hadm_IDs,T_intubs_dict_for_analysis,\n",
    "                                                                           time_series_dict_MetaVision,\n",
    "                                                                           measures = ['FiO2', 'SpO2', 'PaO2', 'PH', 'PaCO2', 'PtoF', 'StoF','PEEP'], T_range= [0,t_range])\n",
    "    measures_firsts_dict_given_T_range_MetaVision.update({t_range: firsts_dict})\n",
    "    firsts_table_results.to_excel('impact_table_metavision_first_{}_hours.xlsx'.format(t_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# **Effect of $T_i$ time window on missingness and measure means:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_effect_on_missing_and_mean_summarizer(measures_means_dict_given_t, measures = ['FiO2', 'PEEP', 'SpO2', 'PaO2', 'PH', 'PaCO2', 'PtoF', 'StoF','static_compliance'],t_list = [2,4,8,12,24]):\n",
    "    \n",
    "    missingness_mean_table = pd.DataFrame(columns = ['missingness', 'mean'])\n",
    "    for measure_name in measures:        \n",
    "        missing_string = ''\n",
    "        mean_string = ''\n",
    "        for t in t_list:\n",
    "            measures_means_dict = measures_means_dict_given_t[t]\n",
    "            ID_list = measures_means_dict.keys()\n",
    "            mean_T_i = []\n",
    "            mean_T_v = []\n",
    "            delta_mean_list = []\n",
    "            for ID in ID_list:\n",
    "                ID_T_i_measure = measures_means_dict[ID][0][measure_name]\n",
    "                ID_T_v_measure = measures_means_dict[ID][1][measure_name]\n",
    "                mean_T_i.append(ID_T_i_measure)\n",
    "                mean_T_v.append(ID_T_v_measure)\n",
    "                delta_mean_list.append(ID_T_i_measure-ID_T_v_measure)\n",
    "                \n",
    "            non_nan_abs_delta_list  = [abs(i) for i in delta_mean_list if ~np.isnan(i)]\n",
    "            non_zero_abs_delta_list = [abs(i) for i in delta_mean_list if (~np.isnan(i)) and (i!=0)]\n",
    "\n",
    "            n_missing       = len(ID_list)-len(non_nan_abs_delta_list)\n",
    "            percent_missing = n_missing/len(ID_list)*100\n",
    "            mean = np.mean(non_zero_abs_delta_list)\n",
    "            missing_string += '{:3,} ({:4.1f}%)\\n'.format(n_missing, percent_missing)\n",
    "            mean_string    += '{:.2f}\\n'.format(mean)\n",
    "        \n",
    "        missingness_mean_table.loc[measure_name, 'missingness'] = missing_string\n",
    "        missingness_mean_table.loc[measure_name, 'mean'] = mean_string\n",
    "    return missingness_mean_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CareVue**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missingness</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FiO2</th>\n",
       "      <td>200 ( 4.3%)\\n132 ( 2.8%)\\n106 ( 2.3%)\\n 93 ( 2.0%)\\n</td>\n",
       "      <td>17.55\\n10.50\\n5.68\\n3.99\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEEP</th>\n",
       "      <td>147 ( 3.2%)\\n 98 ( 2.1%)\\n 81 ( 1.7%)\\n 80 ( 1.7%)\\n</td>\n",
       "      <td>1.62\\n1.04\\n0.61\\n0.41\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpO2</th>\n",
       "      <td>149 ( 3.2%)\\n120 ( 2.6%)\\n 95 ( 2.0%)\\n 81 ( 1.7%)\\n</td>\n",
       "      <td>1.11\\n0.71\\n0.53\\n0.53\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaO2</th>\n",
       "      <td>2,442 (52.4%)\\n1,430 (30.7%)\\n875 (18.8%)\\n721 (15.5%)\\n</td>\n",
       "      <td>82.35\\n49.50\\n31.74\\n25.52\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PH</th>\n",
       "      <td>2,417 (51.9%)\\n1,402 (30.1%)\\n855 (18.4%)\\n705 (15.1%)\\n</td>\n",
       "      <td>0.07\\n0.05\\n0.04\\n0.03\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaCO2</th>\n",
       "      <td>2,442 (52.4%)\\n1,430 (30.7%)\\n875 (18.8%)\\n721 (15.5%)\\n</td>\n",
       "      <td>8.85\\n6.87\\n4.96\\n4.42\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PtoF</th>\n",
       "      <td>3,599 (77.3%)\\n2,944 (63.2%)\\n2,380 (51.1%)\\n2,077 (44.6%)\\n</td>\n",
       "      <td>66.44\\n53.34\\n31.50\\n28.28\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StoF</th>\n",
       "      <td>1,060 (22.8%)\\n539 (11.6%)\\n296 ( 6.4%)\\n250 ( 5.4%)\\n</td>\n",
       "      <td>26.53\\n20.48\\n17.14\\n14.46\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>static_compliance</th>\n",
       "      <td>1,376 (29.5%)\\n1,083 (23.3%)\\n819 (17.6%)\\n722 (15.5%)\\n</td>\n",
       "      <td>9.52\\n8.94\\n3.26\\n4.54\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    missingness  \\\n",
       "FiO2                       200 ( 4.3%)\\n132 ( 2.8%)\\n106 ( 2.3%)\\n 93 ( 2.0%)\\n   \n",
       "PEEP                       147 ( 3.2%)\\n 98 ( 2.1%)\\n 81 ( 1.7%)\\n 80 ( 1.7%)\\n   \n",
       "SpO2                       149 ( 3.2%)\\n120 ( 2.6%)\\n 95 ( 2.0%)\\n 81 ( 1.7%)\\n   \n",
       "PaO2                   2,442 (52.4%)\\n1,430 (30.7%)\\n875 (18.8%)\\n721 (15.5%)\\n   \n",
       "PH                     2,417 (51.9%)\\n1,402 (30.1%)\\n855 (18.4%)\\n705 (15.1%)\\n   \n",
       "PaCO2                  2,442 (52.4%)\\n1,430 (30.7%)\\n875 (18.8%)\\n721 (15.5%)\\n   \n",
       "PtoF               3,599 (77.3%)\\n2,944 (63.2%)\\n2,380 (51.1%)\\n2,077 (44.6%)\\n   \n",
       "StoF                     1,060 (22.8%)\\n539 (11.6%)\\n296 ( 6.4%)\\n250 ( 5.4%)\\n   \n",
       "static_compliance      1,376 (29.5%)\\n1,083 (23.3%)\\n819 (17.6%)\\n722 (15.5%)\\n   \n",
       "\n",
       "                                           mean  \n",
       "FiO2                 17.55\\n10.50\\n5.68\\n3.99\\n  \n",
       "PEEP                   1.62\\n1.04\\n0.61\\n0.41\\n  \n",
       "SpO2                   1.11\\n0.71\\n0.53\\n0.53\\n  \n",
       "PaO2               82.35\\n49.50\\n31.74\\n25.52\\n  \n",
       "PH                     0.07\\n0.05\\n0.04\\n0.03\\n  \n",
       "PaCO2                  8.85\\n6.87\\n4.96\\n4.42\\n  \n",
       "PtoF               66.44\\n53.34\\n31.50\\n28.28\\n  \n",
       "StoF               26.53\\n20.48\\n17.14\\n14.46\\n  \n",
       "static_compliance      9.52\\n8.94\\n3.26\\n4.54\\n  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingness_mean_table_given_t = t_effect_on_missing_and_mean_summarizer(measures_means_dict_given_T_range_CareVue, measures = ['FiO2', 'PEEP', 'SpO2', 'PaO2', 'PH', 'PaCO2', 'PtoF', 'StoF','static_compliance'],t_list = [2,4,8,12])\n",
    "missingness_mean_table_given_t.to_excel('missingness_mean_table_given_t_carevue.xlsx')\n",
    "missingness_mean_table_given_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MetaVision**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingness_mean_table_given_t = t_effect_on_missing_and_mean_summarizer(measures_means_dict_given_T_range_MetaVision, measures = ['FiO2', 'PEEP', 'SpO2', 'PaO2', 'PH', 'PaCO2', 'PtoF', 'StoF','static_compliance'],t_list = [2,4,8,12])\n",
    "missingness_mean_table_given_t.to_excel('missingness_mean_table_given_t_metavision.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "# **Effect  of $T_i$  on oxygenation level:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_intub_effect_on_hypoxia_summarizer(ID_list, measures_means_dict):\n",
    "    '''\n",
    "    In the output, rows are T_i and columns are T_v.\n",
    "    '''\n",
    "    \n",
    "    from collections import Counter\n",
    "    hypoxia_change_from_Ti_to_Tv  = []\n",
    "    \n",
    "    for ID in ID_list:\n",
    "        ID_PtoF_Ti = measures_means_dict[ID][0]['PtoF']\n",
    "        ID_PtoF_Tv = measures_means_dict[ID][1]['PtoF']\n",
    "        \n",
    "        if pd.notnull(ID_PtoF_Ti) & pd.notnull(ID_PtoF_Tv):\n",
    "            if ID_PtoF_Ti<=100:\n",
    "                hypoxia_Ti = 'Severe'\n",
    "            elif ID_PtoF_Ti<=200:\n",
    "                hypoxia_Ti = 'Moderate'\n",
    "            elif ID_PtoF_Ti<=300:\n",
    "                hypoxia_Ti = 'Mild'\n",
    "            else:\n",
    "                hypoxia_Ti = 'Normal'\n",
    "        \n",
    "            if ID_PtoF_Tv<=100:\n",
    "                hypoxia_Tv = 'Severe'\n",
    "            elif ID_PtoF_Tv<=200:\n",
    "                hypoxia_Tv = 'Moderate'\n",
    "            elif ID_PtoF_Tv<=300:\n",
    "                hypoxia_Tv = 'Mild'\n",
    "            else:\n",
    "                hypoxia_Tv = 'Normal'\n",
    "        \n",
    "            ID_hypoxia_change_from_Ti_to_Tv = hypoxia_Ti + '-' + hypoxia_Tv\n",
    "            hypoxia_change_from_Ti_to_Tv.append(ID_hypoxia_change_from_Ti_to_Tv)\n",
    "        else:\n",
    "            pass\n",
    "    total_count = sum(Counter(hypoxia_change_from_Ti_to_Tv).values())\n",
    "    hypoxia_level_matrix = pd.DataFrame(columns = ['Normal','Mild','Moderate','Severe'])\n",
    "    for item, count in Counter(hypoxia_change_from_Ti_to_Tv).items():\n",
    "#         print('{}: {:,}({:.1f}%)'.format(item, count, count/total_count*100))\n",
    "        hypoxia_level_matrix.loc[item.split('-')[0],item.split('-')[1]] =  '{:,} ({:.1f}%)'.format(count, count/total_count*100)\n",
    "    hypoxia_level_matrix= hypoxia_level_matrix.reindex(['Normal','Mild','Moderate','Severe'])\n",
    "    changed_hypoxia_level = sum([count for item, count in Counter(hypoxia_change_from_Ti_to_Tv).items() if item not in ['Mild-Mild','Moderate-Moderate','Severe-Severe','Normal-Normal', ]])\n",
    "    print('n(%) non-missing hypoxia pairs:  {:,} ({:.1f}%)'.format(len(hypoxia_change_from_Ti_to_Tv),100*len(hypoxia_change_from_Ti_to_Tv)/len(ID_list)))\n",
    "    print('n(%) with changed hypoxia level: {:,} ({:.1f}%)'.format(changed_hypoxia_level,changed_hypoxia_level/total_count*100))\n",
    "    return hypoxia_level_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CareVue:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Within 2 hours of intubation: \n",
      "n(%) non-missing hypoxia pairs:  1,058 (22.7%)\n",
      "n(%) with changed hypoxia level: 6 (0.6%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Mild</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>337 (31.9%)</td>\n",
       "      <td>1 (0.1%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mild</th>\n",
       "      <td>NaN</td>\n",
       "      <td>248 (23.4%)</td>\n",
       "      <td>1 (0.1%)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderate</th>\n",
       "      <td>2 (0.2%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>295 (27.9%)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Severe</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 (0.2%)</td>\n",
       "      <td>172 (16.3%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Normal         Mild     Moderate       Severe\n",
       "Normal    337 (31.9%)     1 (0.1%)          NaN          NaN\n",
       "Mild              NaN  248 (23.4%)     1 (0.1%)          NaN\n",
       "Moderate     2 (0.2%)          NaN  295 (27.9%)          NaN\n",
       "Severe            NaN          NaN     2 (0.2%)  172 (16.3%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Within 4 hours of intubation: \n",
      "n(%) non-missing hypoxia pairs:  1,713 (36.8%)\n",
      "n(%) with changed hypoxia level: 8 (0.5%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Mild</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>517 (30.2%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mild</th>\n",
       "      <td>1 (0.1%)</td>\n",
       "      <td>442 (25.8%)</td>\n",
       "      <td>3 (0.2%)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderate</th>\n",
       "      <td>1 (0.1%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512 (29.9%)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Severe</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 (0.2%)</td>\n",
       "      <td>234 (13.7%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Normal         Mild     Moderate       Severe\n",
       "Normal    517 (30.2%)          NaN          NaN          NaN\n",
       "Mild         1 (0.1%)  442 (25.8%)     3 (0.2%)          NaN\n",
       "Moderate     1 (0.1%)          NaN  512 (29.9%)          NaN\n",
       "Severe            NaN          NaN     3 (0.2%)  234 (13.7%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Within 8 hours of intubation: \n",
      "n(%) non-missing hypoxia pairs:  2,277 (48.9%)\n",
      "n(%) with changed hypoxia level: 4 (0.2%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Mild</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>671 (29.5%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mild</th>\n",
       "      <td>NaN</td>\n",
       "      <td>632 (27.8%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderate</th>\n",
       "      <td>1 (0.0%)</td>\n",
       "      <td>2 (0.1%)</td>\n",
       "      <td>734 (32.2%)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Severe</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 (0.0%)</td>\n",
       "      <td>236 (10.4%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Normal         Mild     Moderate       Severe\n",
       "Normal    671 (29.5%)          NaN          NaN          NaN\n",
       "Mild              NaN  632 (27.8%)          NaN          NaN\n",
       "Moderate     1 (0.0%)     2 (0.1%)  734 (32.2%)          NaN\n",
       "Severe            NaN          NaN     1 (0.0%)  236 (10.4%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Within 12 hours of intubation: \n",
      "n(%) non-missing hypoxia pairs:  2,580 (55.4%)\n",
      "n(%) with changed hypoxia level: 11 (0.4%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Mild</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>757 (29.3%)</td>\n",
       "      <td>1 (0.0%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mild</th>\n",
       "      <td>NaN</td>\n",
       "      <td>736 (28.5%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderate</th>\n",
       "      <td>1 (0.0%)</td>\n",
       "      <td>6 (0.2%)</td>\n",
       "      <td>842 (32.6%)</td>\n",
       "      <td>1 (0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Severe</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 (0.1%)</td>\n",
       "      <td>234 (9.1%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Normal         Mild     Moderate      Severe\n",
       "Normal    757 (29.3%)     1 (0.0%)          NaN         NaN\n",
       "Mild              NaN  736 (28.5%)          NaN         NaN\n",
       "Moderate     1 (0.0%)     6 (0.2%)  842 (32.6%)    1 (0.0%)\n",
       "Severe            NaN          NaN     2 (0.1%)  234 (9.1%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.ExcelWriter('hypoxia_matrices_carevue.xlsx') as writer:\n",
    "    for t_range  in [2,4,8,12]:\n",
    "        print('\\nWithin {} hours of intubation: '.format(t_range))\n",
    "        hypoxia_matrix = t_intub_effect_on_hypoxia_summarizer(adult_nonSurg_intubated_carevue_hadm_IDs,measures_means_dict_given_T_range_CareVue[t_range])\n",
    "        display(hypoxia_matrix)\n",
    "        hypoxia_matrix.to_excel(writer,'Within {} hours'.format(t_range))\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MetaVision**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Within 2 hours of intubation: \n",
      "n(%) non-missing hypoxia pairs:  551 (15.3%)\n",
      "n(%) with changed hypoxia level: 3 (0.5%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Mild</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>149 (27.0%)</td>\n",
       "      <td>1 (0.2%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mild</th>\n",
       "      <td>NaN</td>\n",
       "      <td>129 (23.4%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1 (0.2%)</td>\n",
       "      <td>171 (31.0%)</td>\n",
       "      <td>1 (0.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Severe</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99 (18.0%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Normal         Mild     Moderate      Severe\n",
       "Normal    149 (27.0%)     1 (0.2%)          NaN         NaN\n",
       "Mild              NaN  129 (23.4%)          NaN         NaN\n",
       "Moderate          NaN     1 (0.2%)  171 (31.0%)    1 (0.2%)\n",
       "Severe            NaN          NaN          NaN  99 (18.0%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Within 4 hours of intubation: \n",
      "n(%) non-missing hypoxia pairs:  887 (24.6%)\n",
      "n(%) with changed hypoxia level: 13 (1.5%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Mild</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>245 (27.6%)</td>\n",
       "      <td>1 (0.1%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mild</th>\n",
       "      <td>1 (0.1%)</td>\n",
       "      <td>213 (24.0%)</td>\n",
       "      <td>3 (0.3%)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderate</th>\n",
       "      <td>1 (0.1%)</td>\n",
       "      <td>3 (0.3%)</td>\n",
       "      <td>271 (30.6%)</td>\n",
       "      <td>1 (0.1%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Severe</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 (0.3%)</td>\n",
       "      <td>145 (16.3%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Normal         Mild     Moderate       Severe\n",
       "Normal    245 (27.6%)     1 (0.1%)          NaN          NaN\n",
       "Mild         1 (0.1%)  213 (24.0%)     3 (0.3%)          NaN\n",
       "Moderate     1 (0.1%)     3 (0.3%)  271 (30.6%)     1 (0.1%)\n",
       "Severe            NaN          NaN     3 (0.3%)  145 (16.3%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Within 8 hours of intubation: \n",
      "n(%) non-missing hypoxia pairs:  1,244 (34.6%)\n",
      "n(%) with changed hypoxia level: 21 (1.7%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Mild</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>323 (26.0%)</td>\n",
       "      <td>4 (0.3%)</td>\n",
       "      <td>1 (0.1%)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mild</th>\n",
       "      <td>3 (0.2%)</td>\n",
       "      <td>319 (25.6%)</td>\n",
       "      <td>4 (0.3%)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderate</th>\n",
       "      <td>2 (0.2%)</td>\n",
       "      <td>1 (0.1%)</td>\n",
       "      <td>411 (33.0%)</td>\n",
       "      <td>1 (0.1%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Severe</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 (0.4%)</td>\n",
       "      <td>170 (13.7%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Normal         Mild     Moderate       Severe\n",
       "Normal    323 (26.0%)     4 (0.3%)     1 (0.1%)          NaN\n",
       "Mild         3 (0.2%)  319 (25.6%)     4 (0.3%)          NaN\n",
       "Moderate     2 (0.2%)     1 (0.1%)  411 (33.0%)     1 (0.1%)\n",
       "Severe            NaN          NaN     5 (0.4%)  170 (13.7%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Within 12 hours of intubation: \n",
      "n(%) non-missing hypoxia pairs:  1,471 (40.9%)\n",
      "n(%) with changed hypoxia level: 24 (1.6%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Mild</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>393 (26.7%)</td>\n",
       "      <td>4 (0.3%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mild</th>\n",
       "      <td>2 (0.1%)</td>\n",
       "      <td>395 (26.9%)</td>\n",
       "      <td>5 (0.3%)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderate</th>\n",
       "      <td>2 (0.1%)</td>\n",
       "      <td>5 (0.3%)</td>\n",
       "      <td>477 (32.4%)</td>\n",
       "      <td>3 (0.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Severe</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 (0.2%)</td>\n",
       "      <td>182 (12.4%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Normal         Mild     Moderate       Severe\n",
       "Normal    393 (26.7%)     4 (0.3%)          NaN          NaN\n",
       "Mild         2 (0.1%)  395 (26.9%)     5 (0.3%)          NaN\n",
       "Moderate     2 (0.1%)     5 (0.3%)  477 (32.4%)     3 (0.2%)\n",
       "Severe            NaN          NaN     3 (0.2%)  182 (12.4%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.ExcelWriter('hypoxia_matrices_metavision.xlsx') as writer:\n",
    "    for t_range  in [2,4,8,12]:\n",
    "        print('\\nWithin {} hours of intubation: '.format(t_range))\n",
    "        hypoxia_matrix = t_intub_effect_on_hypoxia_summarizer(adult_nonSurg_intubated_metavision_hadm_IDs,measures_means_dict_given_T_range_MetaVision[t_range])\n",
    "        display(hypoxia_matrix)\n",
    "        hypoxia_matrix.to_excel(writer,'Within {} hours'.format(t_range))\n",
    "    writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
